<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yuxin Chen</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="Education.html">Education</a></div>
<div class="menu-item"><a href="Group.html">Group</a></div>
<div class="menu-item"><a href="Teaching.html">Teaching</a></div>
<div class="menu-item"><a href="Publications_year.html">Publications</a></div>
<div class="menu-item"><a href="Software.html">Software</a></div>
<div class="menu-item"><a href="Resume_Yuxin_CHEN.pdf">Resume</a></div>
<div class="menu-item"><a href="InvitedTalk.html">Talks</a></div>
<div class="menu-item"><a href="Workshops.html">Workshops</a></div>
<div class="menu-item"><a href="reading_group/index.html">Reading&nbsp;group</a></div>
</td>
<td id="layout-content">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3857157-7', 'auto');
  ga('send', 'pageview');

</script>
<h1>Yuxin Chen</h1>

<table class="imgtable"><tr><td>
<img src="images/photo_Dec2019.jpg" alt="alt text" width="200 px" height="IMGLINKTARGET" />&nbsp;</td>
<td align="left"><p>I am an assistant professor of <a href="http://ee.princeton.edu/">Electrical Engineering</a>, and an associated faculty member of <a href="http://www.cs.princeton.edu/">Computer Science</a>, <a href="https://www.pacm.princeton.edu/">Applied and Computational Mathematics</a>, and the <a href="https://csml.princeton.edu/">Center for Statistics and Machine Learning</a> at Princeton University. 
</p>
<p>Prior to joining Princeton in Spring 2017, I was a postdoctoral scholar in the Department of Statistics at Stanford University supervised by Prof. <a href="http://statweb.stanford.edu/~candes/">Emmanuel Candès</a>.  I completed my Ph.D. in Electrical Engineering at Stanford University in Fall 2014, under the supervision of  Prof. <a href="http://ee.stanford.edu/~andrea">Andrea Goldsmith</a>. 
</p>
<p><b>Research areas</b>: mathematical foundations of data science, optimization, high-dimensional statistics, statistical learning, information theory,  and their applications to medical imaging and computational biology.</p>
<p><b>Contact:</b> <br />
C330, Engineering Quad <br />
Princeton University, Princeton, NJ 08544 <br /></p>
<p>Email: yuxin dot chen at princeton dot edu</p>
</td></tr></table>

<h2>Recent news</h2>
<ul>
<li><p>My first student <a href="http://www.princeton.edu/~congm/index.html">Cong Ma</a> will join the Department of Statistics at the University of Chicago as an assistant professor in 2021. Congratulations, Cong!!!     </p>
</li>
</ul>
<ul>
<li><p>Our paper <a href="https://www.pnas.org/content/pnas/116/46/22931.full.pdf">&ldquo;Inference and Uncertainty Quantification for Noisy Matrix Completion&rdquo;</a> has been accepted to Proceedings of the National Academy of Sciences (PNAS), 2019 (direct submission) <a href="publications/MC_inference.pdf">[full version]</a>.</p>
</li>
</ul>
<ul>
<li><p>Our paper <a href="https://link.springer.com/content/pdf/10.1007%2Fs10208-019-09429-9.pdf">&ldquo;Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind Deconvolution&rdquo;</a> has been accepted to Foundations of Computational Mathematics, 2019.</p>
</li>
</ul>
<ul>
<li><p>Our (invited) overview article <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8811622">&ldquo;Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview&rdquo;</a> has been published in IEEE Transactions on Signal Processing, 2019 <a href="publications/NcxOverview_Arxiv.pdf">[full version]</a>. </p>
</li>
</ul>
<ul>
<li><p>Yuejie Chi and I gave a tutorial on <a href="slides/itw2018_tutorial.pdf">&lsquo;&lsquo;Taming Nonconvexity in Information Science&rsquo;&rsquo;</a> at ITW 2018.</p>
</li>
</ul>
<ul>
<li><p>I received the 2019 AFOSR Young Investigator Program (YIP) Award. </p>
</li>
</ul>
<h2>Teaching</h2>
<ul>
<li><p>Sping 2020: <a href="http://www.princeton.edu/~yc5/syllabus_information_signals_Spring2020.pdf">ELE201: Information and Signals</a> <br /></p>
</li>
<li><p>Fall 2019: <a href="http://www.princeton.edu/~yc5/ele522_optimization/index.html">ELE522: Large-Scale Optimization for Data Science</a> (Princeton Engineering Commendation List for Outstanding Teaching) <br /></p>
</li>
<li><p>Fall 2018: <a href="http://www.princeton.edu/~yc5/ele538_math_data/index.html">ELE538: Mathematics of High-Dimensional Data</a> (Princeton Engineering Commendation List for Outstanding Teaching) <br /></p>
</li>
<li><p>Fall 2018:  <a href="http://www.princeton.edu/~yc5/ele382_SSP/index.html">ELE382: Probabilistic Systems and Information Processing</a> <br /></p>
</li>
<li><p>Spring 2018: <a href="http://www.princeton.edu/~yc5/ele522_optimization/index.html">ELE538C: Large-Scale Optimization for Data Science</a> (Princeton Engineering Commendation List for Outstanding Teaching) <br />
</p>
</li>
</ul>
<h2>Selected recent papers</h2>
<ul>
<li><p>C. Cheng, Y. Wei, <u>Y. Chen</u>, <a href="publications/eigenvector_inference.pdf">&ldquo;Inference for Linear Forms of Eigenvectors under
Minimal Eigenvalue Separation: Asymmetry and Heteroscedasticity,&rdquo;</a> 2020. <a href="publications/eigenvector_inference.pdf">[paper]</a><a href="slides/inference_asymmetry_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u>, J. Fan, C. Ma, Y. Yan,  <a href="publications/RPCA_noise.pdf">&ldquo;Bridging Convex and Nonconvex Optimization in Robust PCA: Noise, Outliers, and Missing Data,&rdquo;</a> 2020. <a href="publications/RPCA_noise.pdf">[paper]</a></p>
</li>
</ul>
<ul>
<li><p>C. Cai, G. Li, H. V. Poor, <u>Y. Chen</u>, <a href="publications/NonconvexTC.pdf">&ldquo;Nonconvex Low-Rank Symmetric Tensor Completion from Noisy Data,&rdquo;</a> 2019 (appeared in part in NeurIPS 2019). <a href="publications/NonconvexTC.pdf">[paper]</a> </p>
</li>
</ul>
<ul>
<li><p>C. Cai, G. Li, Y. Chi, H. V. Poor, <u>Y. Chen</u>, <a href="publications/unbalanced_PCA.pdf">&ldquo;Subspace Estimation from Unbalanced and Incomplete Data Matrices:
<img class="eq" src="eqs/3673726929016744179-130.png" alt="ell_{2,infty}" style="vertical-align: -6px" /> Statistical Guarantees,&rdquo;</a>  2019. <a href="publications/unbalanced_PCA.pdf">[paper]</a></p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u>, J. Fan, C. Ma, Y. Yan,  <a href="https://www.pnas.org/content/pnas/116/46/22931.full.pdf">&ldquo;Inference and Uncertainty Quantification for Noisy Matrix Completion,&rdquo;</a> <i>Proceedings of the National Academy of Sciences (PNAS)</i>, vol. 116, no. 46, pp. 22931–22937, Nov. 2019 (direct submission). <a href="publications/MC_inference.pdf">[Arxiv]</a><a href="https://www.pnas.org/content/pnas/early/2019/10/29/1910053116.full.pdf">[PNAS version]</a><a href="slides/NoisyMC_Inference_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u>, Y. Chi, J. Fan, C. Ma, Y. Yan,  <a href="publications/NoisyMC.pdf">&ldquo;Noisy Matrix Completion: Understanding Statistical Guarantees for Convex Relaxation via Nonconvex Optimization,&rdquo;</a>  2019. <a href="publications/NoisyMC.pdf">[paper]</a><a href="slides/NoisyMC_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u>, C. Cheng, J. Fan,  <a href="publications/asymmetric_eigens.pdf">&ldquo;Asymmetry Helps: Eigenvalue and Eigenvector Analyses of Asymmetrically Perturbed Low-Rank Matrices,&rdquo;</a> accepted to <i>Annals of Statistics</i>, 2020. <a href="publications/asymmetric_eigens.pdf">[paper]</a><a href="slides/asymmetry_eigs_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p>Y. Chi, Y. Lu, <u>Y. Chen</u>, <a href="publications/NcxOverview_Arxiv.pdf">&ldquo;Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview,&rdquo;</a> <i>IEEE Transactions on Signal Processing</i>, vol. 67, no. 20, pp. 5239-5269, October 2019 <b>(invited overview article)</b>. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8811622">[TSP version]</a><a href="publications/NcxOverview_Arxiv.pdf">[Arxiv]</a><a href="slides/Nonconvex_overview_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u>, Y. Chi, J. Fan, C. Ma, <a href="https://link.springer.com/article/10.1007/s10107-019-01363-6">&ldquo;Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval,&rdquo;</a> <i>Mathematical Programming</i>, vol. 176, no. 1-2, pp. 5-37, July 2019.   <a href="publications/random_init_PR.pdf">[Arxiv]</a><a href="slides/random_init_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p>C. Ma, K. Wang, Y. Chi, <u>Y. Chen</u>, <a href="https://link.springer.com/content/pdf/10.1007%2Fs10208-019-09429-9.pdf">&ldquo;Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind Deconvolution,&rdquo;</a> accepted to <i>Foundations of Computational Mathematics</i>, 2017 (appeared in part in ICML 2018).  <a href="publications/ImplicitReg_main.pdf">[main text]</a><a href="publications/ImplicitReg_supp.pdf">[supplement]</a><a href="publications/ImplicitReg.pdf">[full paper (Arxiv)]</a><a href="slides/implicit_reg_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u>, J. Fan, C. Ma, K. Wang, <a href="publications/topK_AOS.pdf">&ldquo;Spectral Method and Regularized MLE Are Both Optimal for Top-<i>K</i> Ranking,&rdquo;</a> <i>Annals of Statistics</i>, vol. 47, no. 4, pp. 2204-2235, August 2019. <a href="publications/topK.pdf">[Arxiv]</a><a href="slides/topK_slides.pdf">[slides]</a></p>
</li>
</ul>
<ul>
<li><p>P. Sur, <u>Y. Chen</u>, E. J. Candes, <a href="publications/LRT_HighDim_PTRF.pdf">&ldquo;The Likelihood Ratio Test in High-Dimensional Logistic Regression Is Asymptotically a <i>Rescaled</i> Chi-Square,&rdquo;</a> <i>Probability Theory and Related Fields</i>, vol. 175, no. 1-2, pp.487–558, October 2019. <a href="slides/LRT_HighDim_slides.pdf">[slides]</a><a href="codes/Code_LRT.zip">[code]</a> </p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u> and E. J. Candes, <a href="publications/nonconvexAlign.pdf">&ldquo;The Projected Power Method: An Efficient Algorithm for Joint Alignment from Pairwise Differences,&rdquo;</a> <i>Communications on Pure and Applied Mathematics</i>, vol. 71, issue 8, pp. 1648-1714, August 2018. <a href="slides/Alignment_slides.pdf">[slides]</a><a href="codes/code_NonconvexAlign.zip">[code]</a> </p>
</li>
</ul>
<ul>
<li><p><u>Y. Chen</u> and E. J. Candes, <a href="publications/TruncatedWF_CPAM.pdf">&ldquo;Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems,&rdquo;</a> <i>Communications on Pure and Applied Mathematics</i>, vol. 70, issue 5, pp. 822-883, May 2017  (appeared in part in NIPS 2015 <b>(oral)</b>). <a href="slides/TWF_slides.pdf">[slides]</a><a href="http://princeton.edu/~yc5/TWF/">[website]</a></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2020-04-04 17:14:10 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
